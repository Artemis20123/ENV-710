## binomial regression

when you care more about the proportion of dummies, instead of the individual success

logistic: y = 1 or 0

-   2 responses: (total number, number of success) / proportion of success is given

binomial: y = x out of n trails

-   the situation is count data as ys (similar to poisson regression), but we only care about the binary results (success or not)?

in what condition to use logistic regression? and in what using binomial regression?

### Phenology

```{r}
trees <-read.csv("data/pheno.csv")
b0 <- glm(cbind(tr, n-tr) ~ factor(czone) * ht, family = binomial, data = trees)

b1 <- update(b0, .~. -factor(czone):ht)
```

the overdisperson issue is unlikely when the residual deviance is less than the df

how to evaluate/ explain the null and residual deviance of these two regressions?

how is the DHARMa::test of dispersion different from the original overdispersion test?

-   what is the hypothesis meaning

overdisperson: value \>1

explain the results: on the log-odds scale, on the odds scale

exp() separate parameters will reflect their every unit adding effect

to calculate the total effect or make predictions, we should exp(intercept + log-odd parameter), instead of exp() them separately.

#### Visualization

y = log(tr/(n-tr)): log odds

inv.logit() to get the probability of certain conditions (e.g., zone2, tree height = 10m)

```{r}
b <- coef(b1)


library(ggplot2)
ggplot(data = trees, aes(x = ht, y = log(tr/(n-tr)))) +
  geom_point(aes(color = factor(czone))) +
  stat_function(fun = function(x){b[1] + b[4]*x}, color = 'blue') +
  stat_function(fun = function(x){b[1] + b[2] + b[4]*x}, color = 'red') +
  stat_function(fun = function(x){b[1] + b[3] + b[4]*x}, color = 'black') +
  theme_bw() +
  scale_color_manual("Climate/n Zone", values = c('blue', 'red', 'black'))
```

```{r}
ggplot(data = trees, aes(x = ht, y = tr/(n-tr))) +
  geom_point(aes(color = factor(czone))) +
  stat_function(fun = function(x){exp(b[1] + b[4]*x)}, color = 'blue') +
  stat_function(fun = function(x){exp(b[1] + b[2] + b[4]*x)}, color = 'red') +
  stat_function(fun = function(x){exp(b[1] + b[3] + b[4]*x)}, color = 'black') +
  theme_bw() +
  scale_color_manual("Climate/n Zone", values = c('blue', 'red', 'black')) +
  labs(title = "odds scale")
```

```{r}
library(boot)

ggplot(data = trees, aes(x = ht, y = tr/n)) +
  geom_point(aes(color = factor(czone))) +
  stat_function(fun = function(x){inv.logit(b[1] + b[4]*x)}, color = 'blue') +
  stat_function(fun = function(x){inv.logit(b[1] + b[2] + b[4]*x)}, color = 'red') +
  stat_function(fun = function(x){inv.logit(b[1] + b[3] + b[4]*x)}, color = 'black') +
  theme_bw() +
  scale_color_manual("Climate/n Zone", values = c('blue', 'red', 'black')) +
  theme(legend.position = c(0.1,0.8)) +
  labs(title = "probability scale", x= "height, m", y = "probability of flowering")
```
