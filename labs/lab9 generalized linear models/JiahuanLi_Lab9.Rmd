---
title: 'ENV 710: Lab 9'
author: "Jiahuan Li"
date: "Spring 2023"
output: pdf_document
knitr:
  code_folding: hide
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, eval = TRUE, warning = F, message = FALSE)
pacman::p_load(ggplot2, GGally)
library(ggplot2)
library(GGally)
```

# Problem 1

## Hypothesis

The null hypothesis for problem 1 is that there is no significant relationship between the predictors (aircraft type, bomb load, and aircrew experience) and the response variable (damage of attack aircraft during the Vietnam War). The alternative hypothesis is that there is a significant relationship between at least one of the predictors and the response variable.

## Method

### Data preview

```{r, warning=FALSE,message=FALSE}
air <- read.csv("./labs/lab9 Generalized Linear Models/AircraftDat.csv")
# air <- read.csv("AircraftDat.csv")
air$x1 <- factor(air$x1)
```

```{r, message=FALSE, fig.cap="Preview of Dataset"}
ggpairs(air)
summary(air)
```

From the plot and table, we can observe that the dependent variable varies from 1 to 30, which is appropriate because the dependent variable needs to be a non-negative integer for Poisson regression. It is also not normally distributed, which is also expected since the Poisson distribution is a discrete distribution. Furthermore, two of the independent variables, bomb load (in tons) and total months of aircrew experience, are continuous, and the other independent variable x1 is a categorical variable indicating the type of aircraft (A-4 or A-6). Moreover, there do not seem to be clear linear relationships between the dependent variable and the independent variables in the raw data - that is fine too, because that is not an assumption of Poisson regression.

### Initial model

Poisson regression is utilized in this case since the response variable consists of count data. Therefore, the initial model encompassing all potential influencing variables is formulated as follows:

```{r}
lm1 <- glm(y ~ as.factor(x1) + x2 + x3,
          data = air, family = poisson)
summary(lm1)
```

The regression summary reveals that only the `x2` terms are statistically significant, suggesting that the model is likely not the minimum adequate model for the problem.

### Model reduction

To identify the minimum adequate model, I constructed models for all possible combinations of variables and used LRT tests and AIC values to assess the performance of each model. The results are presented below:

```{r}
lm2.1<- update(lm1, ~.-as.factor(x1))

lm2.2 <- update(lm1, ~.-x2)

lm2.3 <- update(lm1, ~.-x3)

lm3.1 <- glm(y ~ as.factor(x1),
          data = air, family = poisson)

lm3.2 <- glm(y ~ x2,
          data = air, family = poisson)

lm3.3 <- glm(y ~ x3,
          data = air, family = poisson)

library(lmtest)

lrtest(lm1,lm2.2)
lrtest(lm1, lm2.1, lm3.2)
lrtest(lm1,lm2.3,lm3.1)
```

Based on the first LRT tests, it was found that removing `x2` from the model resulted in a significantly different reduced model compared to the original model, indicating that `x2` is an important variable in the model. Using the same method, results of all three tests jointly showed that only keeping the term `x2` in the regression is appropriate. As shown in the second test, the reduction process did not significantly impact the original model.

The minimum adequate model can also be justified using the Akaike Information Criterion.

```{r}
AIC(lm1,lm2.1,lm2.2,lm2.3,lm3.1,lm3.2,lm3.3)
```

We can find that the model with only `x2` as its predictor has the smallest AIC number (86.90196).

### Minimum adequate model

```{r echo=TRUE}
summary(lm3.2)
```

## Results

From the regression report, it can be concluded that bomb load has a significant positive impact on the damage of attack aircraft ($z$ = 4.942, $p$ \< 0.001). The coefficient is 0.23112, which means that for a one-unit increase in tons of bomb load, the expected damage of attack aircraft will increase by a factor of 1.26 ($exp^{0.23112}$). And the intercept does not have a practical interpretation since it assumes a bomb load of zero, which is not possible.

The deviance residuals are a measure of how well the model fits the data. The residual deviance of 29.206 on 28 degrees of freedom, which are close, indicates that the model does not have a great concern about the over-dispersion issue. The null deviance is the deviance of a model with no predictors, and the residual deviance is the deviance of the fitted model. The difference between the two deviances represents the reduction in deviance achieved by the model. In this case, the reduction in deviance is 53.883 - 29.206 = 24.677, which indicates that the model is a significant improvement over the null model.

## Assumptions check

```{r}
mean(residuals(lm3.2))
```

The calculated mean error is very small (-0.1716) and close to 0 as expected, indicating that the model has a good fit to the data. Besides, the residuals are nearly independent and normally distributed as shown in the diagnosis plots. The plots also indicates that there is no overdispersion issue as 1) no more than 5% of the standardized residuals are greater than 2 in the scale-location plot; and 2) there are no outlier observations in the leverage plot. The dispersive test result also supported this with an overdispersion ratio of 1.037 less than 2.

```{r, fig.cap="Assumption plots"}
par(mfrow=c(2,2), mar = c(3.8, 4, 3, 2))
plot(lm3.2)
```

```{r, message=FALSE}
library(AER)
dispersiontest(lm3.2)
```

Then I tested the goodness of fit of the model using the chi-square goodness-of-fit test. I compared the residual deviance of the reduced model to a chi-square distribution with the same degrees-of-freedom. It returns a value of 0.40, which is not statistically significant and indicates the model is good.

```{r include=FALSE}
pchisq(lm3.2$deviance, lm3.2$df.residual, lower.tail=F)
```

The pseudo-$R^2$ test returns a value of 0.58, which is slightly less than the initial model with all the predictors (0.62). But the close and reletively high proportion still indicates the reduced model has a good ability to explain the variation in the dependent variable.

```{r}
library(DescTools)
DescTools::PseudoR2(lm3.2, c("VeallZimmermann"))
DescTools::PseudoR2(lm1, c("VeallZimmermann"))
```

## Visualization

The figure below displays the impact of bomb load on the damage of attack aircraft.

```{r, fig.cap= "Impact of bomb load on the damage of attack aircraft",fig.align='center'}

eq1 <- function(x)
{ exp(coef(lm3.2)[1] + coef(lm3.2)[2] * x)}

ggplot(air) +
geom_point(aes(x = x2, y = y)) +
stat_function(aes(x = x2), fun = eq1, geom = "line") +
labs(x = "Bomb load (ton)", y = "Damage of attack aircraft")
```

# Problem 2

## Hypothesis

The null hypothesis for this question is that there is no association between bird keeping and lung cancer, after accounting for age and smoking. The alternative hypothesis is that bird keeping is associated with a higher rate of lung cancer, after accounting for age and smoking.

## Method

### Data preview

```{r}
library(Sleuth3)
data(case2002)

case2002$cancer <- ifelse(case2002$LC == "NoCancer", 0, 1)
```

```{r, message=FALSE, fig.cap="Preview of Dataset"}
ggpairs(case2002)
```

From the plot, we can observe that there might be some interactions among the predictors. Thus, we begin our initial model include all the potential interactions.

### Initial model

Logistic regression is utilized in this case. The initial model encompassing all potential influencing variables and interactions is formulated as follows:

```{r}
lmm1 <- glm(cancer ~ factor(BK)*AG*YR, family=binomial, data=case2002)
summary(lmm1)
```

All the predictors are not statistically significant in the report, suggesting that the model is not the minimum adequate model for the problem.

### Model reduction

I used a stepwise variable selection method, removing predictors with higher p-values first, until the remaining predictors all had p-values below a certain threshold (e.g., 0.05). This approach helps to simplify the model and avoid overfitting, while retaining predictors that are most strongly associated with the response variable.

```{r include=FALSE}
lmm2 <- update(lmm1, ~.-AG)
summary(lmm2)
lmm3 <- update(lmm2, ~.-factor(BK):AG)
summary(lmm3)
lmm4 <- update(lmm3, ~.-factor(BK):YR)
summary(lmm4)
lmm5 <- update(lmm4, ~.-factor(BK):YR:AG)
summary(lmm5)
lmm6 <- update(lmm5, ~.-YR:AG)
```

At last, only the predictor `BK` and `YR` are included in the reduced model.

```{r echo=FALSE}
summary(lmm6)
```

```{r}
lrtest(lmm1, lmm2, lmm3, lmm4, lmm5, lmm6)
AIC(lmm1, lmm2, lmm3, lmm4, lmm5, lmm6)
```

We can justify this model by referring to the LRT test and AIC number. Specifically, the AIC numbers for model 4,5, and 6 are very close with a gap less than 2. It is acceptable and, thus, the simplest model (model 6) should be our choice.

## Results

The regression model is a logistic regression with cancer as the response variable and bird-keeping status (BK) and years smoked (YR) as predictors. The intercept (coefficient for the reference level of the factor variable BK , which is "Bird" in this case, and the numeric variable YR, which equals to 0 in this case) is -1.70460 in log-odds scale and 0.18 in odd scale, which is statistically significant (p \< 0.01).

The hypothesis that bird keepers have higher rates of lung cancer than non-bird keepers is supported by the regression result. Specifically, changing from the bird keeper group to the non-bird keeper group will cause a 1.48 decrease in log-odds scale ($z$ = -3.727, $p$ \< 0.001). It implies that the probability of getting lung cancer will decrease by 77%.

Besides, for a one-unit increase in smoking, the expected change in log-odds is 0.05825 ($z$ = 3.458, $p$ \< 0.001), which corresponds to a change of 1.06 in the odds of survival. And the coefficient can be interpreted as: for each additional year smoked, the odds of getting lung cancer change by a factor of 1.06 (or increase by 6%), holding bird keeping status constant.

## Assumptions check

To test the goodness of fit, `pchisq`, `hoslem`, and `PseudoR2` tests have been conducted. Values larger than 0.05 (a certain significant level) shown in the first two tests indicate that the null hypotheses (the model is good) cannot be rejected. The relatively large R2 value of the reduced model (0.29), with 0.33 for the original one, also reveals that the model is good.

```{r echo=FALSE}
library(ResourceSelection)
pchisq(lmm6$deviance, lmm6$df.residual, lower=F)
hoslem.test(case2002$cancer, fitted(lmm6))

DescTools::PseudoR2(lmm6, c("VeallZimmermann"))
DescTools::PseudoR2(lmm1, c("VeallZimmermann"))
```

```{r}
mean(residuals(lmm6))
vif(lmm6)
```

The calculated mean error is very small (-0.087) and close to 0 as expected, indicating that the model has a good fit to the data. Furthermore, the variance inflation factors (VIF) are around 1.03 for BK and YR in this case, indicating that multicollinearity is not an issue. That is, the independent variables are not highly correlated with each other.

Also, the traditional diagnosis plots and DHARMa plots did not report potential conflicts with the model assumptions.

```{r, fig.cap="Assumption plots", fig.pos="h"}
par(mfrow=c(2,2), mar = c(3.8, 4, 3, 2))
plot(lmm6)
```

```{r, fig.cap="DHARMa plots", fig.pos="h"}
library(DHARMa)
lm6 <- simulateResiduals(fittedModel = lmm6) 
plot(lm6)
```

## Visualization

The figure displays the impacts of bird keeper and year of smoke on lung cancer rate.

```{r, fig.cap= "Impacts of bomb of bird keeper and year of smoke on lung cancer rate",fig.align='center', fig.pos="h"}
library(boot)

jcoPalette <- c("#0073C2FF", "#EFC000FF", "#868686FF", "#CD534CFF",
"#7AA6DCFF", "#003C67FF", "#8F7700FF", "#3B3B3BFF", "#A73030FF",
"#4A6990FF")
# plot the data points
plot(jitter(case2002$YR), case2002$cancer, las=1, pch=21, cex=1.2, bg="grey",
     xlab = "Year of smoking", ylab = "Lung cancer risk", cex.axis = 0.8,
     cex.lab = 0.8)

# add curves for bird and no-bird
x <- seq(min(case2002$YR), max(case2002$YR), length = 50)
curve(expr = inv.logit(lmm6$coef[1] + lmm6$coef[2] + lmm6$coef[3]*x), add=T,
      lwd=2, col= jcoPalette[9], lty = 1)
curve(expr = inv.logit(lmm6$coef[1] + lmm6$coef[3]*x), add=T,
      lwd=2, col= jcoPalette[10], lty = 2)
points(case2002$YR, fitted(lmm6))

# add a legend
legend("topright", legend=c("Bird keeper", "Non-bird keeper"), lty=c(1, 2), col=c(jcoPalette[9], jcoPalette[10]), bty="n", cex=0.8)
```

## Prediction

```{r echo=TRUE}
inv.logit (coef(lmm6)[1] +coef(lmm6)[3]*32)
inv.logit(coef(lmm6)[1])
```

The probability of having lung cancer is 54.0% if you are a bird keeper and have smoked for 32 years. And the probability of the intercept is 15.4%, which means the individual is a bird keeper and have not smoked.

# Problem 3

## Hypothesis

We want to test whether well depth, distance from the mine, and site affect the proportion of contaminated wells at a site. $H_0:$ The proportion of contaminated wells is not affected by well depth, distance from the mine, and site. $H_a:$ The proportion of contaminated wells is affected by at least one of the factors including well depth, distance from the mine, and/or site.

## Method

### Data preview

```{r, message=FALSE,warning=FALSE, fig.cap="Preview of Dataset", fig.pos="h"}
water <- read.csv("./labs/lab9 Generalized Linear Models/water.csv")
ggpairs(water)
```

### Model

Because the site effect is considered in this model and the response can be summarized in two groups, a random effect logistic model should be established.

```{r}
library(lme4)
llm <- glmer(cbind(Y, N-Y) ~ well_depth + dist_mine + (1|site), data = water, family = binomial)
```

```{r, warning=FALSE}
summary(llm)
```

There is no need to reduce the model since all the predictors are significant.

## Results

The model has a log-likelihood of -45.9, an AIC of 99.8, and a BIC of 107.4. The AIC and BIC values indicate that the model is a good fit for the data. The scaled residuals have a mean of zero and a standard deviation of one, which indicates that the model assumptions are met. The response variable is a binomial variable that represents the number of contaminated wells out of the total number of tested wells at each site. The model includes three fixed effects: well_depth, dist_mine, and an intercept, and a random intercept for each site (grouped by the n variable).

The coefficient for well_depth is 0.06869 ($z$ = 3.059, $p$ \< 0.05). This indicates that, holding the distance to mine constant, a one-unit increase in well depth is associated with a 0.06869 increase in the log-odds of a well being contaminated (increase by a factor of 1.07 in the odd scale). The coefficient for dist_mine is -0.12855 ($z$ = -11.215, $p$ \< 0.05). This indicates that, holding well depth constant, a one-unit increase in the distance to mine is associated with a -0.12855 decrease in the log-odds scale, which is a 12% decrease in the odd scale. The correlation between well_depth and dist_mine is -0.122, which indicates that there is a weak negative correlation between the two predictor variables.

In conclusion, the model suggests that well_depth and dist_mine have significant effects on the proportion of contaminated wells at a site. Specifically, increasing well depth is associated with an increase in the probability of a well being contaminated, while increasing the distance to mine is associated with a decrease in the probability of a well being contaminated.

## Assumptions check

```{r,warning=FALSE}
mean(residuals(llm))
vif(llm)

library(MuMIn)
MuMIn::r.squaredGLMM(llm)
```

The calculated mean error is very small (0.025) and close to 0, indicating that the model has a good fit to the data. Furthermore, the variance inflation factors (VIF) are around 1 for both well_depth and dist_mine in this case, indicating that multicollinearity is not an issue.

Besides, the values for R2m (0.987) and R2c (0.999) show that the fixed and random effects of the model explain a substantial proportion of the variation in the response variable. The differences between the full and null models are quite large, indicating that the model provides a good fit to the data.

We can also justify the goodness of the model from the DHARMa residuals plots. No conflicts with the assumptions are reported by the plots.

```{r, fig.cap="DHARMa plots", fig.pos="h"}
library(DHARMa)
llm1 <- simulateResiduals(fittedModel = llm) 
plot(llm1)
```

```{r, fig.cap="zero inflation test", fig.height=6, fig.pos="h"}
testZeroInflation(llm1)
```

The "ratioObsSim" value in the report indicates the ratio of observed zeros to expected zeros based on simulations under the null hypothesis that the model is correctly specified. A value close to 1 suggests a good fit between the observed and expected distributions of zeros. In this case, the value is 0.927, which indicates a slight deviation from the expected distribution of zeros. The "p-value" in the report represents the probability of observing a ratio as extreme or more extreme than the observed ratio, assuming that the model is correctly specified. In this case, the p-value is 0.528, which is greater than the commonly used significance level of 0.05. Therefore, we do not reject the null hypothesis that the model is correctly specified.

Overall, the results of the DHARMa zero-inflation test suggest that the model adequately accounts for zero-inflation in the data, and that the observed and expected distributions of zeros are similar. Thus, it is not an issue in this case. Also, the result of nonparametric dispersion test indicates the overdispersion issue does not need to be concerned in this model.

## Visualization

Since the proportion of random effect is small in this case, only the main fixed effects of the two predictors are visualized in the two graphs, holding the other variable constant as its mean value.

```{r, fig.cap= "Impacts of well depth on well pollution",fig.align='center'}
llm2 <- glm(cbind(Y, N-Y) ~ well_depth + dist_mine, data = water, family = binomial)

eq3.dep <- function(x)
{ inv.logit(coef(llm2)[1] + coef(llm2)[2] * x + coef(llm2)[3] * mean(water$dist_mine))}

ggplot(water) +
geom_point(aes(x = well_depth, y = Y/N)) +
stat_function(aes(x = well_depth), fun = eq3.dep, geom = "line") +
labs(x = "Well depth", y = "Well pollution possibility")
```

```{r, fig.cap= "Impacts of distance to mine on well pollution",fig.align='center'}
eq3.dis <- function(x)
{ inv.logit(coef(llm2)[1] + coef(llm2)[2] * mean(water$well_depth) + coef(llm2)[3] * x)}

ggplot(water) +
geom_point(aes(x = dist_mine, y = Y/N)) +
stat_function(aes(x = dist_mine), fun = eq3.dis, geom = "line") +
labs(x = "Distance to mine", y = "Well pollution possibility")
```

\newpage

```{r, ref.label=knitr::all_labels(),echo=TRUE,eval=FALSE}

```
